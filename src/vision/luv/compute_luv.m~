function compute_luv
% PHOW_CALTECH101 Image classification in the Caltech-101 dataset
%   This program demonstrates how to use VLFeat to construct an image
%   classifier on the Caltech-101 data. The classifier uses PHOW
%   features (dense SIFT), spatial histograms of visual words, and a
%   Chi2 SVM. To speedup computation it uses VLFeat fast dense SIFT,
%   kd-trees, and homogeneous kernel map. The program also
%   demonstrates VLFeat PEGASOS SVM solver, although for this small
%   dataset other solvers such as LIBLINEAR can be more efficient.
%
%   By default 15 training images are used, which should result in
%   about 64% performance (a good performance considering that only a
%   single feature type is being used).
%
%   Call PHOW_CALTECH101 to train and test a classifier on a small
%   subset of the Caltech-101 data. Note that the program
%   automatically downloads a copy of the Caltech-101 data from the
%   Internet if it cannot find a local copy.
%   Edit the PHOW_CALTECH101 file to change the program configuration.
%
%   To run on the entire dataset change CONF.TINYPROBLEM to FALSE.
%
%   The Caltech-101 data is saved into CONF.CALDIR, which defaults to
%   'data/caltech-101'. Change this path to the desired location, for
%   instance to point to an existing copy of the Caltech-101 data.
%
%   The program can also be used to train a model on custom data by
%   pointing CONF.CALDIR to it. Just create a subdirectory for each
%   class and put the training images there. Make sure to adjust
%   CONF.NUMTRAIN accordingly.
%
%   Intermediate files are stored in the directory CONF.DATADIR. All
%   such files begin with the prefix CONF.PREFIX, which can be changed
%   to test different parameter settings without overriding previous
%   results.
%
%   The program saves the trained model in
%   <CONF.DATADIR>/<CONF.PREFIX>-model.mat. This model can be used to
%   test novel images independently of the Caltech data.
%
%     load('data/baseline-model.mat') ; # change to the model path
%     label = model.classify(model, im) ;
%

% AUTORIGHTS

% Add texton path where to find anigauss
%path(path, '/home/elia.bruni/google/data_sets/mir/1m/scripts/texton')



conf.calDir = '/Users/eliabruni/data/esp/test/input/esp-sample-1' ;
conf.dataDir = '/Users/eliabruni/data/esp/test/ouput/luv' ;
conf.autoDownloadData = false ;
conf.numTrain = 30 ;
conf.numTest = 4 ;
conf.numClasses = 1 ;
conf.numWords = 10 ;
conf.numSpatialX = 1 ;
conf.numSpatialY = 1 ;
conf.quantizer = 'kdtree' ;
%conf.phowOpts = {'Verbose', 2, 'Step', 5} ;

conf.prefix = 'baseline' ;
conf.randSeed = 1 ;


conf.vocabPath = fullfile(conf.dataDir, [conf.prefix '-vocab.mat']) ;
conf.modelPath = fullfile(conf.dataDir, [conf.prefix '-model.mat']) ;
conf.resultPath = fullfile(conf.dataDir, [conf.prefix '-result']) ;

randn('state',conf.randSeed) ;
rand('state',conf.randSeed) ;
vl_twister('state',conf.randSeed) ;

% --------------------------------------------------------------------
%                                                           Setup data
% --------------------------------------------------------------------
classes = dir(conf.calDir) ;
classes = classes([classes.isdir]) ;
classes = {classes.name} ;

images = {} ;
imageClass = {} ;
for ci = 1:length(classes)
    ims = dir(fullfile(conf.calDir, classes{ci}, '*.jpg'))' ;
    ims = cellfun(@(x)fullfile(classes{ci},x),{ims.name},'UniformOutput',false) ;
    images = {images{:}, ims{:}} ;
    imageClass{end+1} = ci * ones(1,length(ims)) ;
end
imageClass = cat(2, imageClass{:}) ;
model.classes = classes ;

model.classes = classes ;
model.numSpatialX = conf.numSpatialX ;
model.numSpatialY = conf.numSpatialY ;
model.quantizer = conf.quantizer ;
model.vocab = [] ;

% --------------------------------------------------------------------
%                                                     Train vocabulary
% --------------------------------------------------------------------


if ~exist(conf.vocabPath)
    
    % TODO:
    % Preallocate singleDescrs for efficiency!
    singleDescrs = {} ;
    
    imageSize = 256;
    for ii = 1:conf.numTrain
        
        im = imread(fullfile(conf.calDir, images{ii}));
        im = standarizeImage(im) ;
        %im = im2double(im) ;
        %im = imresize(im, [imageSize imageSize], 'bilinear') ;
        if ndims(im) == 2
            im = cat(3,im,im,im);
        end
        descrs = rgb2luv(im);
        
        singleDescrs{ii} = vl_colsubset(single(descrs), length(descrs)) ;
        
    end
    %singleDescrs
    
    % Quantize the descriptors to get the visual words
    
    singleDescrs = vl_colsubset(cat(2, singleDescrs{:}), 10e4) ;
    singleDescrs = single(singleDescrs) ;
    
    
    vocab = vl_kmeans(singleDescrs, conf.numWords, 'verbose','algorithm', 'lloyd') ;
    
    save(conf.vocabPath, 'vocab') ;
else
    load(conf.vocabPath) ;
end

model.vocab = vocab ;

if strcmp(model.quantizer, 'kdtree')
    model.kdtree = vl_kdtreebuild(vocab) ;
end

% --------------------------------------------------------------------
%                                           Compute spatial histograms
% --------------------------------------------------------------------

blockSize = 1000 ;
listLength = length(images)/blockSize ;
histsNames = [] ;
for jj = 1:listLength
    histsNames{jj} = randseq(30) ;
end
histsNames = sort(histsNames) ;


hists = {} ;
iter = 0 ;
for ii = 1:length(images)
    if mod(ii, 100) == 0
        fprintf('Processing %s (%.2f %%)\n', images{ii}, 100 * ii / length(images)) ;
    end
    
    im = imread(fullfile(conf.calDir, images{ii})) ;
    hists{ii - (iter * blockSize)} = getImageDescriptor(model, im);
    
    
    if mod(ii, blockSize) == 0
        tmpHists = cat(2, hists{:}) ;
        tmpHists = rot90(tmpHists) ;
        histName = histsNames{ii/blockSize} ;
        eval([histName ' = tmpHists;' ]) ;
        conf.prefix = histsNames{ii/blockSize} ;
        conf.histPath = fullfile(conf.dataDir, [conf.prefix '.mat']) ;
        save(conf.histPath, strcat(histsNames{ii/blockSize})) ;
        eval([histName ' = {};' ]) ;
        hists = {} ;
        tmpHists = {} ;
        histName = {} ;
        iter = iter + 1 ;
        
    end
    
end
tmpHists = cat(2, hists{:}) ;
tmpHists = rot90(tmpHists) ;

eval(['ZZZZZZZZZZZZZZZZZZZZ' '= tmpHists;' ]) ;
% hists = cat(2, hists{:}) ;
conf.prefix = 'ZZZZZZZZZZZZZZZZZZZZ' ;
conf.histPath = fullfile(conf.dataDir, [conf.prefix '.mat']) ;
save(conf.histPath,'ZZZZZZZZZZZZZZZZZZZZ') ;

% -------------------------------------------------------------------------
function im = standarizeImage(im)
% -------------------------------------------------------------------------

im = im2single(im) ;
im = imresize(im, [480 NaN]) ;



% -------------------------------------------------------------------------
function hist = getImageDescriptor(model, im)
% -------------------------------------------------------------------------

imageSize = 480;
%im = standarizeImage(im) ;
%im = im2double(im) ;
im = imresize(im, [480 10], 'bilinear') ;
if ndims(im) == 2
    im = cat(3,im,im,im);
end
%width = size(im,2) ;
%height = size(im,1) ;
numWords = size(model.vocab, 2) ;
size(numWords)
%numWords = 10 ;

% get PHOW features
[framesdescrs = rgb2luv(im);
descrs = cat(1, 100 , 100);
size(descrs)
%[frames, descrs] = vl_phow(im, model.phowOpts{:}) ;

% quantize appearance
switch model.quantizer
    case 'vq'
        [drop, binsa] = min(vl_alldist(model.vocab, single(descrs)), [], 1) ;
    case 'kdtree'
        binsa = double(vl_kdtreequery(model.kdtree, model.vocab, ...
            single(descrs),...
            'MaxComparisons', 15)) ;
end

% quantize location
%width = size(im, 2) ;
%height = size(im, 1) ;


%binsx = vl_binsearch(linspace(1,width,model.numSpatialX+1), frames(1,:)) ;
%binsy = vl_binsearch(linspace(1,height,model.numSpatialY+1), frames(2,:)) ;

bins = sub2ind([model.numSpatialY, model.numSpatialX, numWords], ...
    binsa) ;


hist = zeros(model.numSpatialY * model.numSpatialX * numWords, 1) ;
hist = vl_binsum(hist, ones(size(bins)), bins) ;
hist = single(hist / sum(hist)) ;
