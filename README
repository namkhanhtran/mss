Thiss project is for creating a multimodal semantic space from the 
combination of images and text as explained in Bruni, Tran and Baroni 2011.

To extract textual information we use traditional corpus-based models. 
We store it in a matrix, with words as rows and contextual elements as 
columns/dimensions (Turney and Pantel, 2010).

To extract visual information from images, we use “bag of visual words” (BoVW) 
(Sivic and Zisserman, 2003; Csurka et al., 2004; Nister and Stewenius, 2006; 
Bosch et al., 2007; Yang et al., 2007). Also here we can store the visual 
information onto a matrix, with words as rows and visual words as columns/dimensions.
